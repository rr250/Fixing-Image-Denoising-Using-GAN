{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMpDZAyLCaBx"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOkF16FRmuC2"
   },
   "source": [
    "You are given the original and degraded versions of a few images. Your task is to write a GAN which can fix the degraded images.\n",
    "\n",
    "Complete the function `fix` at the end of the \"Evaluation\" block so that it can take a degraded image, and return a fixed image (that looks as much like the original non-degraded version as possible).\n",
    "\n",
    "Before submission, get this notebook in a state such that the `fix` function can directly be called on an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "insnPyAeRC0x"
   },
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoYMgagKCFdn"
   },
   "source": [
    "## Intended Structure after Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCHJeTjnhj05"
   },
   "source": [
    "Run the blocks in this section to get the following directory structure:\n",
    "```\n",
    "/content\n",
    "│\n",
    "└───rephrase-pubfig831\n",
    "    │\n",
    "    └───correct\n",
    "    │   │\n",
    "    │   └───train\n",
    "    │   │   │\n",
    "    │   │   └───Adam Sandler\n",
    "    │   │   │   │   train__000001-000000.jpg\n",
    "    │   │   │   │   train__000001-000001.jpg\n",
    "    │   │   │   │   train__000001-000002.jpg\n",
    "    │   │   │   │   ...\n",
    "    │   │   │\n",
    "    │   │   └───Alec Baldwin\n",
    "    │   │   │   │   train__000002-000000.jpg\n",
    "    │   │   │   │   train__000002-000001.jpg\n",
    "    │   │   │   │   ...\n",
    "    │   │   │\n",
    "    │   │   └───Angelina Jolie\n",
    "    │   │   │   │   train__000003-000000.jpg\n",
    "    │   │   │   │   train__000003-000001.jpg\n",
    "    │   │   │   │   ...\n",
    "    │   │   │\n",
    "    │   │   │ ...\n",
    "    │   │\n",
    "    │   └───test\n",
    "    │       │\n",
    "    │       └───Adam Sandler\n",
    "    │       │   │   test__000001-000000.jpg\n",
    "    │       │   │   test__000001-000001.jpg\n",
    "    │       │   │   ...\n",
    "    │       │\n",
    "    │       └───Alec Baldwin\n",
    "    │       │   │   test__000002-000000.jpg\n",
    "    │       │   │   ...\n",
    "    │       │\n",
    "    │       └───Angelina Jolie\n",
    "    │       │   │   test__000003-000000.jpg\n",
    "    │       │   │   ...\n",
    "    │       │\n",
    "    │       │ ...\n",
    "    │\n",
    "    │\n",
    "    └───degraded\n",
    "        │   <Same directory structure as 'correct'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58tM3kFPNZ0Z"
   },
   "source": [
    "Every image in the degraded directory is a degraded version of the image with the same name in the correct directory. e.g. `/content/rephrase-pubfig831/degraded/Adam Sandler/train__000001-000002.jpg` is the degraded version of `/content/rephrase-pubfig831/correct/Adam Sandler/train__000001-000002.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LUrGJB04RF4d"
   },
   "source": [
    "## Installation (pip etc)\n",
    "Add any other installation commands you want to in this block. **Restart Runtime** after this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3ljp1DHRNt7"
   },
   "outputs": [],
   "source": [
    "!pip install tensorlayer\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade tensorflow-gpu\n",
    "!pip install numpy==1.16.1\n",
    "!pip install GPUtil\n",
    "!pip install tqdm\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNJbKsnjR74d"
   },
   "source": [
    "## Downloading and Generating Dataset\n",
    "Run this block only once. Do not modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "ozoy8Olklwaj",
    "outputId": "23d22a17-bab5-45f1-d1fb-eedd9ec20514",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def degrade(path: str) -> None:\n",
    "    \"\"\"Load image at `input_path`, distort and save as `output_path`\"\"\"\n",
    "    SHIFT = 2\n",
    "    image = cv2.imread(path)\n",
    "    to_swap = np.random.choice([False, True], image.shape[:2], p=[.8, .2])\n",
    "    swap_indices = np.where(to_swap[:-SHIFT] & ~to_swap[SHIFT:])\n",
    "    swap_vals = image[swap_indices[0] + SHIFT, swap_indices[1]]\n",
    "    image[swap_indices[0] + SHIFT, swap_indices[1]] = image[swap_indices]\n",
    "    image[swap_indices] = swap_vals\n",
    "    cv2.imwrite(path, image)\n",
    "\n",
    "!wget http://briancbecker.com/files/downloads/pubfig83lfw/pubfig83lfw_raw_in_dirs.zip\n",
    "!unzip -q pubfig83lfw_raw_in_dirs.zip\n",
    "!rm pubfig83lfw_raw_in_dirs.zip\n",
    "!mkdir rephrase-pubfig831\n",
    "!mv pubfig83lfw_raw_in_dirs rephrase-pubfig831/correct\n",
    "!rm -r rephrase-pubfig831/correct/distract\n",
    "!cp -r rephrase-pubfig831/correct rephrase-pubfig831/degraded\n",
    "\n",
    "for image_path in tqdm(glob('rephrase-pubfig831/degraded/*/*/*.jpg')):\n",
    "  degrade(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kz5BM22VralE"
   },
   "source": [
    "# **Checking Free Memory**\n",
    "This block is just so that you can have an idea of the resources you have at hand on the Google Collab system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZoMS9HMX6G9D",
    "outputId": "e7328380-7da2-4b24-84ba-05df9f7106ee"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "gpu = GPU.getGPUs()[0]\n",
    "process = psutil.Process(os.getpid())\n",
    "print(f\"Gen RAM: Free {humanize.naturalsize(psutil.virtual_memory().available)} | Proc size {humanize.naturalsize(process.memory_info().rss)}\")\n",
    "print(f\"GPU RAM: Free {gpu.memoryFree:.0f}MB | Used {gpu.memoryUsed:.0f}MB | Util {gpu.memoryUtil*100:.0f}% | Total {gpu.memoryTotal:.0f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMubMpKy15ac"
   },
   "source": [
    "# **Main Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jW8X7mEUIPJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import scipy, multiprocessing\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import (Input, Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, Flatten, Dense)\n",
    "from tensorlayer.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64iQHp_uliTH"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4DoUU8GYJes"
   },
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    train_hr_img_lists=glob('rephrase-pubfig831/correct/train/*/*.jpg')\n",
    "    train_hr_imgs=[]\n",
    "    i=1\n",
    "    for train_hr_img_list in train_hr_img_lists:\n",
    "        train_hr_imgs.append(tl.vis.read_image(train_hr_img_list))  \n",
    "        # i+=1\n",
    "        # if(i==1000):\n",
    "        #   break\n",
    "    def generator_train():\n",
    "        for img in train_hr_imgs:\n",
    "            yield img\n",
    "    def _map_fn_train(img):\n",
    "        hr_patch = tf.image.random_crop(img, [250, 250, 3])\n",
    "        hr_patch = tf.image.resize(hr_patch, size=[250, 250])\n",
    "        hr_patch = hr_patch / (255. / 2.)\n",
    "        hr_patch = hr_patch - 1.\n",
    "        hr_patch = tf.image.random_flip_left_right(hr_patch)\n",
    "        lr_patch = tf.image.resize(hr_patch, size=[250, 250])\n",
    "        return lr_patch, hr_patch\n",
    "    train_ds = tf.data.Dataset.from_generator(generator_train, output_types=(tf.float32))\n",
    "    train_ds = train_ds.map(_map_fn_train, num_parallel_calls=multiprocessing.cpu_count())\n",
    "    train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "    train_ds = train_ds.prefetch(buffer_size=2)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bSV-9eYyfbX2"
   },
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqLOT8BUsAaW"
   },
   "source": [
    "### **Constants and Hyperparemeters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBghpOPT7Dea"
   },
   "source": [
    "Since Google Colab doesn't have **good resources we should use lower batch_size and less epochs** otherwise with my calculations training might take approximately half a year.\n",
    "**I tried for 10 epochs due to time restrictions and could see minute improvements** but to see good results we have to try atleast 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "S8NNBxqO4qPH",
    "outputId": "c0d3c349-5e5d-45db-b7b1-10bbc0144189"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_epoch_init = 10\n",
    "n_epoch = 100\n",
    "# if you have better resources and time\n",
    "# batch_size = 16\n",
    "# n_epoch_init = 200\n",
    "# n_epoch = 2000\n",
    "lr_init = 1e-4\n",
    "beta1 = 0.9\n",
    "lr_decay = 0.1\n",
    "decay_every = 2\n",
    "shuffle_buffer_size = 128\n",
    "save_dir = \"samples\"\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "checkpoint_dir = \"models\"\n",
    "tl.files.exists_or_mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQr7M263s-CE"
   },
   "source": [
    "### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLjLc0INPJY6"
   },
   "outputs": [],
   "source": [
    "def get_G(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    g_init = tf.random_normal_initializer(1., 0.02)\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(16, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init)(nin)\n",
    "    temp = n\n",
    "\n",
    "    # B residual blocks\n",
    "    for i in range(4):\n",
    "        nn = Conv2d(16, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n",
    "        nn = Conv2d(16, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "        nn = BatchNorm2d(gamma_init=g_init)(nn)\n",
    "        nn = Elementwise(tf.add)([n, nn])\n",
    "        n = nn\n",
    "\n",
    "    n = Conv2d(16, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=g_init)(n)\n",
    "    n = Elementwise(tf.add)([n, temp])\n",
    "    # B residual blacks end\n",
    "\n",
    "    n = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init)(n)\n",
    "    #n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    n = Conv2d(64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init)(n)\n",
    "    #n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init)(n)\n",
    "    G = Model(inputs=nin, outputs=nn)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_u7Eq3yltYld"
   },
   "source": [
    "### Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQ6tsJqgi-Gd"
   },
   "outputs": [],
   "source": [
    "def get_D(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "    df_dim = 8\n",
    "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(df_dim, (4, 4), (2, 2), act=lrelu, padding='SAME', W_init=w_init)(nin)\n",
    "\n",
    "    n = Conv2d(df_dim * 2, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 4, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 16, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 32, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 16, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    nn = BatchNorm2d(gamma_init=gamma_init)(n)\n",
    "\n",
    "    n = Conv2d(df_dim * 2, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 2, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=gamma_init)(n)\n",
    "    n = Elementwise(combine_fn=tf.add, act=lrelu)([n, nn])\n",
    "\n",
    "    n = Flatten()(n)\n",
    "    no = Dense(n_units=1, W_init=w_init)(n)\n",
    "    D = Model(inputs=nin, outputs=no)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVjtttv0fKhp"
   },
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqssKHGgIqij"
   },
   "source": [
    "For Discriminator and Generatot we are going to use Sigmoid Cross-Entropy\n",
    "We are also going to use vgg19 features and use them in our loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uD0xLY_FfRRO"
   },
   "outputs": [],
   "source": [
    "# d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real))\n",
    "# d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake))\n",
    "# d_loss = d_loss1 + d_loss2\n",
    "# g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\n",
    "# mse_loss = tl.cost.mean_squared_error(fake_patchs, hr_patchs, is_mean=True)\n",
    "# vgg_loss = 2e-6 * tl.cost.mean_squared_error(feature_fake, feature_real, is_mean=True)\n",
    "# g_loss = mse_loss + vgg_loss + g_gan_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHWHhltZfP2r"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCdm4QSkGb2c"
   },
   "source": [
    "We are going to use Adam Optimizer instead of RMSPRop and AdaGrad that's why we will use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhL1Myvmopcg"
   },
   "outputs": [],
   "source": [
    "# g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "# g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "# d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7msb0gPuC2A"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6Ccj64AtlK8"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    G = get_G((batch_size, 250, 250, 3))\n",
    "    D = get_D((batch_size, 250, 250, 3))\n",
    "\n",
    "    lr_v = tf.Variable(lr_init)\n",
    "    g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "    g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "    d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "\n",
    "    G.train()\n",
    "    D.train()\n",
    "\n",
    "    train_ds = get_train_data()\n",
    "\n",
    "    ## initialize learning (G)\n",
    "    n_step_epoch = round(n_epoch_init // batch_size)\n",
    "    for epoch in range(n_epoch_init):\n",
    "        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "            if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n",
    "                break\n",
    "            step_time = time.time()\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_hr_patchs = G(lr_patchs)\n",
    "                mse_loss = tl.cost.mean_squared_error(fake_hr_patchs, hr_patchs, is_mean=True)\n",
    "            grad = tape.gradient(mse_loss, G.trainable_weights)\n",
    "            g_optimizer_init.apply_gradients(zip(grad, G.trainable_weights))\n",
    "            print(\"Epoch: [{}/{}] step: [{}] time: {:.3f}s, mse: {:.3f} \".format(\n",
    "                epoch, n_epoch_init, step, time.time() - step_time, mse_loss))\n",
    "        if (epoch != 0) and (epoch % 1 == 0):\n",
    "            tl.vis.save_images(fake_hr_patchs.numpy(), [4, 4], os.path.join(save_dir, 'train_g_init_{}.png'.format(epoch)))\n",
    "\n",
    "    ## adversarial learning (G, D)\n",
    "    n_step_epoch = round(n_epoch // batch_size)\n",
    "    for epoch in range(n_epoch):\n",
    "        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "            if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n",
    "                break\n",
    "            step_time = time.time()\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                fake_patchs = G(lr_patchs)\n",
    "                logits_fake = D(fake_patchs)\n",
    "                logits_real = D(hr_patchs)\n",
    "                d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real))\n",
    "                d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake))\n",
    "                d_loss = d_loss1 + d_loss2\n",
    "                g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\n",
    "                mse_loss = tl.cost.mean_squared_error(fake_patchs, hr_patchs, is_mean=True)\n",
    "                g_loss = mse_loss + g_gan_loss\n",
    "            grad = tape.gradient(g_loss, G.trainable_weights)\n",
    "            g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n",
    "            grad = tape.gradient(d_loss, D.trainable_weights)\n",
    "            d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n",
    "            print(\"Epoch: [{}/{}] step: [{}] time: {:.3f}s, g_loss(mse:{:.3f}, adv:{:.3f}) d_loss: {:.3f}\".format(\n",
    "                epoch, n_epoch, step, time.time() - step_time, mse_loss, g_gan_loss, d_loss))\n",
    "\n",
    "        # update the learning rate\n",
    "        if epoch != 0 and (epoch % decay_every == 0):\n",
    "            new_lr_decay = lr_decay**(epoch // decay_every)\n",
    "            lr_v.assign(lr_init * new_lr_decay)\n",
    "            log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n",
    "            print(log)\n",
    "\n",
    "        if (epoch != 0):\n",
    "            tl.vis.save_images(fake_patchs.numpy(), [4, 4], os.path.join(save_dir, 'train_g_{}.png'.format(epoch)))\n",
    "            G.save_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "            D.save_weights(os.path.join(checkpoint_dir, 'd.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hnT-iqU-4bnk",
    "outputId": "7b70fd85-2fd7-4217-e38c-84f0603b5df9"
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EloW4JAcyYDJ"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNnCAsPZgyqn"
   },
   "outputs": [],
   "source": [
    "def fix(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function should take a degraded image in BGR format as a 250x250x3\n",
    "    numpy array, and return its fixed version in the same format.\n",
    "    \"\"\"\n",
    "    G = get_G([1, 250, 250, 3])\n",
    "    G.load_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "    G.eval()\n",
    "\n",
    "    image = np.asarray(image, dtype=np.float32)\n",
    "    image = image[np.newaxis,:,:,:]\n",
    "    size = [image.shape[1], image.shape[2]]\n",
    "\n",
    "    outimage = G(image).numpy()\n",
    "    outimage = tf.image.resize(outimage, size=[250, 250])\n",
    "    outimage = np.asarray(outimage, dtype=np.float32)\n",
    "    outimage = outimage[0]\n",
    "    return outimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZk4RFZhnpab"
   },
   "source": [
    "# Results\n",
    "Run this block after done to look at some of the results of the fix function yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "akZdSIK8odKM",
    "outputId": "3ccfadc3-4a74-45c1-ba60-30199ff4e780"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "NUM_DISPLAY = 5\n",
    "\n",
    "files = glob('/content/rephrase-pubfig831/correct/test/*/*.jpg')\n",
    "grid = []\n",
    "\n",
    "for path in random.sample(files, NUM_DISPLAY):\n",
    "  correct = tl.vis.read_image(path)\n",
    "  correct = (correct / 127.5) - 1\n",
    "  split = path.split('/')\n",
    "  degraded = tl.vis.read_image('/'.join([*split[:3], 'degraded', *split[4:]]))\n",
    "  degraded = (degraded / 127.5) - 1\n",
    "  fixed = fix(degraded)\n",
    "  grid.append(np.column_stack([degraded, fixed, correct]))\n",
    "\n",
    "image = np.row_stack(grid)\n",
    "tl.vis.save_image(image, os.path.join(save_dir, 'grid.png'))\n",
    "img=mpimg.imread(os.path.join(save_dir, 'grid.png'))\n",
    "dpi = float(plt.rcParams['figure.dpi'])\n",
    "figsize = image.shape[1] / dpi, image.shape[0] / dpi\n",
    "ax = plt.figure(figsize=figsize).add_axes([0, 0, 1, 1])\n",
    "ax.axis('off')\n",
    "ax.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Rephrase Research Engineer Problem",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
